{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save file_name' and 'file_name's pair\\n    {\\n        'i_123_1321.jpg':[i_124_131.jpg, i_213_213.jpg, v_213_1231,jpg ...],\\n        '1243412':[],\\n        ...\\n    }\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import collections\n",
    "import json\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "meta_cache_dir='/opt/gitserial/tianchi/cache'\n",
    "train_meta_cache_file='train_image_annotation.pkl'\n",
    "val_meta_cache_file='val_image_annotation.pkl'\n",
    "train_video_meta_cache_file='video_image_annotation.pkl'\n",
    "trainval_pos_pair_dict=collections.OrderedDict()\n",
    "for k in train_ann.keys():\n",
    "    trainval_pos_pair_dict[k]={'file_pair':[]}\n",
    "    \n",
    "with open(os.path.join(meta_cache_dir,train_meta_cache_file),'rb') as fid:\n",
    "    train_ann = pickle.load(fid)\n",
    "with open(os.path.join(meta_cache_dir,val_meta_cache_file),'rb') as fid:\n",
    "    val_ann = pickle.load(fid)\n",
    "# with open(os.path.join(meta_cache_dir,train_video_meta_cache_file),'rb') as fid:\n",
    "#     train_video_ann = pickle.load(fid)\n",
    "'''save file_name' and 'file_name's pair\n",
    "    {\n",
    "        'i_123_1321.jpg':[i_124_131.jpg, i_213_213.jpg, v_213_1231,jpg ...],\n",
    "        '1243412':[],\n",
    "        ...\n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/029835.json'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_annotation_files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/104588.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/026748.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/093713.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/025117.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/030888.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/117067.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/001218.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/004369.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/006828.json', '/opt/gitserial/tianchi/data/train_dataset_part1/video_annotation/025937.json']\n"
     ]
    }
   ],
   "source": [
    "root_dir='/opt/gitserial/tianchi'\n",
    "cache_file='video_instance_dict.pkl'\n",
    "data_paths=sorted(glob.glob(os.path.join(root_dir,'data/')+'train_dataset_part?'))\n",
    "video_instance_dict=collections.OrderedDict()\n",
    "\n",
    "video_annotation_files=[]\n",
    "for x in data_paths:\n",
    "    video_annotation_files.extend(glob.glob(x+'/video_annotation/*.json'))\n",
    "print(video_annotation_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:01<00:00, 16187.34it/s]\n"
     ]
    }
   ],
   "source": [
    "video_instance_dict=collections.OrderedDict()\n",
    "instances=set()\n",
    "for i in instances:\n",
    "    video_instance_dict[i]=[]\n",
    "for file in tqdm(video_annotation_files):\n",
    "    with open(file,'r') as fid:\n",
    "        obj = json.load(fid)\n",
    "        for v in obj['frames'] :\n",
    "            annotations=v['annotations']\n",
    "            for annotation in annotations:\n",
    "                instance_id = annotation['instance_id']\n",
    "                instances.add(f'{instance_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/043089.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/085043.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/055298.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/119996.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/029935.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/119502.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/047795.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/028424.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/005397.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/053475.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/072273.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/066891.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/028177.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/030930.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/027000.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/059427.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/029332.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/047705.json',\n",
       " '/opt/gitserial/tianchi/data/train_dataset_part6/video_annotation/008772.json']"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_annotation_files[-20:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_043089_0',\n",
       " 'v_043089_40',\n",
       " 'v_043089_80',\n",
       " 'v_043089_120',\n",
       " 'v_043089_160',\n",
       " 'v_043089_200',\n",
       " 'v_043089_320',\n",
       " 'v_043089_360']"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_instance_dict['24308901']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_instance_dict={k:[] for k in instances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64508"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_instance_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:02<00:00, 14371.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(video_annotation_files):\n",
    "    with open(file,'r') as fid:\n",
    "        obj = json.load(fid)\n",
    "        video_id = obj['video_id']\n",
    "        for v in obj['frames'] :\n",
    "            annotations=v['annotations']\n",
    "            frame_index=v['frame_index']\n",
    "            for annotation in annotations:\n",
    "                instance_id = annotation['instance_id']\n",
    "                xx=video_instance_dict[f'{instance_id}']\n",
    "                xx.append(f'v_{video_id}_{frame_index}')\n",
    "#                 print(xx)\n",
    "                video_instance_dict[instance_id]=xx\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in train_ann.values():\n",
    "    count=0\n",
    "    for i in v:\n",
    "        file_name= i['file_name']\n",
    "        train_dir_num=os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(file_name))))\n",
    "        trainval_pos_pair_dict[item_id]['train_dir_num']=f'{train_dir_num}'\n",
    "        file_pair=set()\n",
    "        item_id=i['annotation']['item_id']\n",
    "        for ann in i['annotation']['annotations']:\n",
    "            viewpoint=ann['viewpoint']\n",
    "            if count == 0 and viewpoint > 0:\n",
    "                count+=1\n",
    "                continue\n",
    "            instance_id=ann['instance_id']\n",
    "            if instance_id > 0:\n",
    "                v_file_list=video_instance_dict.get(f'{instance_id}')\n",
    "                if not v_file_list:\n",
    "                    continue\n",
    "                file_pair.update(v_file_list)\n",
    "                file_pair.add(f'i_{item_id}_{os.path.basename(file_name)}')\n",
    "            trainval_pos_pair_dict[item_id]['file_pair']=sorted(file_pair)\n",
    "#                 print(item_id,train_dir_num,file_pair)\n",
    "        \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "052206\n"
     ]
    }
   ],
   "source": [
    "trainval_pos_pair_dict=collections.OrderedDict()\n",
    "for k in train_ann.keys():\n",
    "    trainval_pos_pair_dict[k]={'file_pair':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainval_pos_pair_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainval_pos_pair_dict\n",
    "with open(os.path.join(meta_cache_dir,'trainval_pos_pair_dict.pkl'),'wb') as fid:\n",
    "    pickle.dump(trainval_pos_pair_dict,fid,pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
